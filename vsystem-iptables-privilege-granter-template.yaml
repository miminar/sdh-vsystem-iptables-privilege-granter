apiVersion: template.openshift.io/v1
kind: Template
metadata:
  name: vsystem-observer
  annotations:
    openshift.io/display-name: "Insecure registry setter for SAP Data Hub Pipeline Modeler"
    description: >
      On Red Hat Enterprise Linux CoreOS, container needs to be run as privileged
      in order to manage iptables on the host system. SAP Data Hub containers named
      "vsystem-iptables" deployed as part of every "vsystem-app" deployment attempt
      to modify iptables rules without having the necessary permissions. This
      template fixes the permissions on-the-fly as the deployments are created.

      The template spawns a pod that observes the particular namespace where
      SAP Data Hub runs and marks each "vsystem-iptables" container in all
      "vsystem-app" deployments as privileged.

      Additionally vsystem-vrep statefulset will be patched to mount `emptyDir` volume
      at `/exports` directory in order to enable NFS exports in the container running
      on top overlayfs which is the default filesystem in RHCOS.

      The template must be instantiated before the installation of SAP Data Hub.
      Also the namespace, where SAP Data Hub will be installed, must exist before
      the instantiation.

      Usage:
        If running in the same namespace as Data Hub, instantiate the template
        as is in the desired namespace:

          oc project $SDH_NAMESPACE
          oc process vsystem-observer | oc create -f -

        If running in a different/new namespace/project, instantiate the
        template with parameters SDH_NAMESPACE and NAMESPACE, e.g.:

          oc new-project $SDH_NAMESPACE
          oc new-project sapdatahub-admin
          oc process vsystem-observer \
              SDH_NAMESPACE=$SDH_NAMESPACE \
              NAMESPACE=sapdatahub-admin | oc create -f -

    openshift.io/provider-display-name: "Red Hat, Inc." 
    openshift.io/documentation-url: "https://access.redhat.com/articles/3630111" 
message: >-
  The vsystem-app observer and patcher will be started. You can watch the progress
  with the following command:

    oc logs -f dc/vsystem-observer
objects:
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: vsystem-observer
    namespace: ${NAMESPACE}
    labels:
      deploymentconfig: vsystem-observer

- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    name: vsystem-observer
    namespace: ${SDH_NAMESPACE}
    labels:
      deploymentconfig: vsystem-observer
  rules:
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments
    - deployments/scale
    - statefulsets
    - statefulsets/scale
    verbs:
    - get
    - list
    - patch
    - watch
  - apiGroups:
    - ""
    resources:
    # necessary to get the configured registry out of secrets/installer-config
    - secrets
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - get
    - list
  # mandatory permissions if running in a different namespace
  - apiGroups:
    - ""
    resources:
    - namespaces
    - namespaces/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    - project.openshift.io
    resources:
    - projects
    verbs:
    - get

- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    namespace: ${SDH_NAMESPACE}
    name: vsystem-observer-${ROLE_BINDING_SUFFIX}
    labels:
      deploymentconfig: vsystem-observer
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: vsystem-observer
    namespace: ${SDH_NAMESPACE}
  subjects:
  - kind: ServiceAccount
    name: vsystem-observer
    namespace: ${NAMESPACE}

- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: vsystem-observer-2-node-reader-${ROLE_BINDING_SUFFIX}
    labels:
      deploymentconfig: vsystem-observer
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node-reader
  subjects:
  - kind: ServiceAccount
    name: vsystem-observer
    namespace: ${NAMESPACE}

- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    name: vsystem-observer
    namespace: ${NAMESPACE}
    labels:
      deploymentconfig: vsystem-observer
  spec:
    selector:
      deploymentconfig: vsystem-observer
    replicas: 1
    strategy:
      type: Rolling
    triggers:
    - type: "ConfigChange"
    template:
      metadata:
        labels:
          deploymentconfig: vsystem-observer
          target: "vsystem-app.datahub.sap.com"
      spec:
        containers:
        - env:
          - name: SDH_NAMESPACE
            value: ${SDH_NAMESPACE}
          - name: DRY_RUN
            value: ${DRY_RUN}
          image: "${BASE_IMAGE}:${BASE_IMAGE_TAG}"
          name: vsystem-observer
          command:
          - /bin/bash
          args:
          - "-c"
          - |
            set -euo pipefail
            IFS=$'\n\t'
            if [[ -n "${SDH_NAMESPACE:-}" ]]; then
              export HOME="$(mktemp -d)"  # so that oc can create $HOME/.kube/ directory
              oc project "${SDH_NAMESPACE}"
            else
              SDH_NAMESPACE="$(oc project -q 2>/dev/null|| :)"
            fi
            # support both 3.x and 4.x output formats
            version="$(oc version --short 2>/dev/null || oc version)"
            serverVersion="$(sed -n 's/^\([sS]erver.*:\|[oO]pen[sS]hift\) v\([0-9]\+\.[0-9]\+\).*/\2/p' \
                              <<<"$version" | head -n 1)"
            clientVersion="$(sed -n 's/^\([cC]lient.*:\|oc\) v\([0-9]\+\.[0-9]\+\).*/\2/p' \
                              <<<"$version" | head -n 1)"
            # translate k8s 1.13 to ocp 4.1
            if [[ "${serverVersion:-}" =~ ^1\.([0-9]+)$ ]]; then
              serverVersion="4.$((${BASH_REMATCH[1]} - 12))"
            fi
            if [[ -z "${clientVersion:-}" ]]; then
              printf 'WARNING: Failed to determine oc client version!\n' >&2
            elif [[ "${serverVersion}" != "${clientVersion}" ]]; then
              printf 'WARNING: Client version != Server version (%s != %s).\n' "$clientVersion" "$serverVersion" >&2
              printf '         Please reinstantiate this template with the correct BASE_IMAGE_TAG parameter (e.g. v%s)."\n' >&2 \
                "$serverVersion"
            elif [[ "${serverVersion}" =~ ^3\. ]]; then
              printf 'No need to patch vsystem pods on OpenShift ${serverVersion}. Exiting.\n'
            fi
            function terminate() {
              # terminate all the process in the container once one observer dies
              kill -9 -- `ps -ahx | awk '{print $1}' | grep -v -F "$BASHPID" | tac`
            }
            function observe() {
              oc observe --listen-addr=:11252 statefulset &
              oc observe --listen-addr=:11251 deploy      &
              while true; do
                sleep 0.1
                if [[ "$(jobs -r | wc -l)" -lt 2 ]]; then
                  terminate
                fi
              done
            }
            function getPatchedNodeKeyValueForPod() {
              local podName="$1"
              local nodeName="$(oc get -o jsonpath=$'{.spec.nodeName}\n' "pod/${podName}")"
              oc get -o jsonpath="$nodeName:"$'{.status.nodeInfo.bootID}\n' "node/$nodeName"
            }
            function getPatchedNodeKeyValuesForDeployment() {
              local deploymentName="$1"
              local uuid="$(oc get -o go-template=$'{{index .metadata.labels "vsystem.datahub.sap.com/uuid"}}\n' "deploy/${deploymentName}")"
              local name
              while IFS=: read -u 4 -r name phase;
              do
                [[ "$phase" == Running ]] || continue
                getPatchedNodeKeyValueForPod "$name"
              done 4< <(oc get pods -l "vsystem.datahub.sap.com/uuid=$uuid" \
                          -o go-template=$'{{range .items}}{{.metadata.name}}:{{.status.phase}}\n{{end}}')
            }
            function updatePatchedNodes() {
              local line
              local nodeName
              local cleanup="$( [[ ! -e /tmp/patched-nodes ]] && echo $? || echo $?; )"
              while read -r line; do
                if grep -q -F "^$line\$" /tmp/patched-nodes; then
                  continue
                fi
                if [[ "$cleanup" == 1 ]]; then
                  nodeName="${line%%:*}"
                  sed -i "/^$nodeName/d" /tmp/patched-nodes
                fi
                printf '%s\n' "$line" >> /tmp/patched-nodes
              done
            }
            if printf '%s\n' "${DRY_RUN:-}" | grep -q -i '^\s*\(y\(es\)\?\|true\|1\)\s*$'; then
              DRY_RUN=1
            else
              DRY_RUN=0
            fi
            function runOrLog() {
              if [[ "${DRY_RUN}" == 1 ]]; then
                echo "$@"
              else
                "$@"
              fi
            }
            gotmplarr=(
              '{{range $di, $d := .items}}'
                '{{if eq .kind "Deployment"}}'
                  # vsystem-app deployment
                  '{{if eq (index .metadata.labels "datahub.sap.com/app-component") "vsystem-app"}}'
                    '{{range $i, $c := .spec.template.spec.containers}}'
                      '{{if eq .name "vsystem-iptables"}}'
                        '{{$d.kind}}/'
                        '{{with $s := $d.status}}'
                          '{{with $s.replicas}}'
                            '{{with $s.availableReplicas}}'
                              '{{if and (eq $s.replicas .) (and (gt . 0.1) (eq . $s.readyReplicas))}}'
                                'ready'
                              '{{else}}'
                                'unready'
                              '{{end}}'
                            # when .status.availableReplicas is undefined
                            '{{else}}'
                              'unready'
                            '{{end}}'
                          # when .status.replicas is undefined
                          '{{else}}'
                            'unready'
                          '{{end}}'
                        '{{end}}'
                       $':{{$i}}:{{not $c.securityContext.privileged}}\n'
                      '{{end}}'
                    '{{end}}'
                  '{{end}}'
                '{{else}}'
                  # vsystem-vrep statefulset
                  '{{if eq .metadata.name "vsystem-vrep"}}'
                    '{{.kind}}'
                    '{{range $i, $c := .spec.template.spec.containers}}'
                      '{{if eq $c.name "vsystem-vrep"}}'
                        ':{{$i}}'
                        '{{range $vmi, $vm := $c.volumeMounts}}'
                          '{{if eq $vm.mountPath "/exports"}}'
                            ':{{$vm.name}}'
                          '{{end}}'
                        '{{end}}'
                      '{{end}}'
                    '{{end}}'
                    $'\n'
                  '{{end}}'
                '{{end}}'
              '{{end}}'
            )
            lackingPermissions=0
            for perm in get/nodes get/projects get/pods get/secrets \
                      watch/deployments get/deployments watch/statefulsets get/statefulsets \
                      patch/deployments patch/statefulsets;
            do
              if ! oc auth can-i "${perm%%/*}" "${perm##*/}" >/dev/null; then
                printf 'Cannot "%s" "%s", please grant the needed permissions' >&2 "${perm%%/*}" "${perm##*/}"
                printf ' to vsystem-observer service account!\n'
                lackingPermissions=1
              fi
            done
            [[ "${lackingPermissions:-0}" == 1 ]] && terminate
            if [[ -n "${SDH_NAMESPACE:-}" ]]; then
              printf 'Watching namespace "%s" for vsystem-apps deployments...\n' "$SDH_NAMESPACE"
            fi
            while IFS=' ' read -u 3 -r _ _ _ _ _ name; do
              [[ -z "${name:-}" ]] && continue
              ( oc get deploy/"$name" statefulset/"$name" \
                    -o go-template="$(printf '%s' "${gotmplarr[@]}")" 2>/dev/null ||: ; ) | \
                  while IFS=: read -r kind index rest;
              do
                case "${kind,,}" in
                deployment/*)
                  if [[ "$rest" == "true" ]]; then
                    allPatched=1
                    for kv in `getPatchedNodeKeyValuesForDeployment "$name"`; do
                      if ! grep -q -F "$kv" /tmp/patched-nodes 2>/dev/null; then
                        allPatched=0
                        break
                      fi
                    done
                    if [[ "$allPatched" == 1 ]]; then
                      printf 'Not patching deployment/%s because all the affected' >&2 "$name"
                      printf ' nodes already run patched containers ...\n' >&2
                      continue
                    fi
                    printf 'Patching container #%d in deployment/%s to make its pods privileged ...\n' \
                        "$index" "$name" >&2
                    runOrLog oc patch "deploy/$name" --type json -p '[{
                      "op": "add",
                      "path": "/spec/template/spec/containers/'"$index"'/securityContext/privileged",
                      "value": true
                    }]'
                  else
                    printf 'Container #%d in deployment/%s already patched, skipping ...\n' "$index" "$name" >&2
                    if [[ "${kind##*/}" == "ready" ]]; then
                      getPatchedNodeKeyValuesForDeployment "$name" | updatePatchedNodes
                    fi
                  fi
                  ;;
                statefulset)
                  if [[ -n "${index:-}" && -n "${rest:-}" ]]; then
                    printf 'statefulset/vsystem-vrep already patched, skipping ...\n' >&2
                  else
                    printf 'Adding emptyDir volume to statefulset/vsystem-vrep ...\n' >&2
                    runOrLog oc patch "statefulset/vsystem-vrep" --type json -p '[{
                      "op": "add",
                      "path": "/spec/template/spec/containers/'"$index"'/volumeMounts/0",
                      "value": {"mountPath": "/exports", "name": "exports-volume"}
                    }, {
                      "op": "add",
                      "path": "/spec/template/spec/volumes/0",
                      "value": {"emptyDir": {}, "name": "exports-volume"}
                    }]'
                  fi
                  ;;
                esac
              done
            done 3< <(observe)
        restartPolicy: Always
        serviceAccount: vsystem-observer
        serviceAccountName: vsystem-observer

parameters:
  - name: BASE_IMAGE
    required: true
    value: quay.io/openshift/origin-cli
    description: >
      Base image containing the command line utilities suitable for interaction
      with the OpenShift cluster. It must contain at least oc and bash
      binaries.
  - name: BASE_IMAGE_TAG
    description: >
      The tag of BASE_IMAGE to pull. The tag shall correspond to the OpenShift release of the cluster.
    required: true
    value: "4.1"
  - name: DRY_RUN
    description: >
      If set to true, no action will be performed. The pod will just print what would have been
      executed.
    required: false
    value: "false"
  - name: SDH_NAMESPACE
    description: >
      The name of the SAP Data Hub namespace to manage. Defaults to the current
      one. It must be set only in case the observer is running in a differnt
      namespace (see NAMESPACE).
  - name: NAMESPACE
    description: >
      The desired namespace, where the vsystem-app observer shall run. Defaults to
      the current one. Needs to be set only if running the observer outside of
      SDH_NAMESPACE.
  - name: ROLE_BINDING_SUFFIX
    description: >
      A random suffix for the new RoleBinding's name. No need to edit.
    generate: expression
    from: '[a-z0-9]{5}'
